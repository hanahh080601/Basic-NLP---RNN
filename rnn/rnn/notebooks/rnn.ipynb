{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bap/hana/Basic-NLP-RNN/rnn/rnn\n"
     ]
    }
   ],
   "source": [
    "%cd /home/bap/hana/Basic-NLP-RNN/rnn/rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    '''\n",
    "    Config class defines dataset path and hyperparameters.\n",
    "    '''\n",
    "    data_train_url = 'dataset/shakespeare_train.txt'\n",
    "    data_val_url = 'dataset/shakespeare_valid.txt'\n",
    "    n_hidden = 512\n",
    "    n_layers = 2\n",
    "    epochs = 25 \n",
    "    n_seqs = 128\n",
    "    n_steps = 100\n",
    "    lr = 0.001\n",
    "    clip = 5\n",
    "    cuda = False\n",
    "    dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    '''\n",
    "    Load data from data path, preprocess (tokenize & one-hot encode) and get data in array type.\n",
    "    '''\n",
    "    def __init__(self, data_train_url = Config.data_train_url, data_val_url = Config.data_val_url):\n",
    "        with io.open (data_train_url, 'r') as f:\n",
    "            self.text_train = f.read()\n",
    "        with io.open (data_val_url, 'r') as f:\n",
    "            self.text_val = f.read()\n",
    "\n",
    "    def char_tokenize(self):\n",
    "        self.chars = tuple(set(self.text_train))\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        self.train_data = np.array([self.char2int[ch] for ch in self.text_train])\n",
    "        self.val_data = np.array([self.char2int[ch] for ch in self.text_val])\n",
    "\n",
    "    def one_hot_encode(self, arr, n_labels):\n",
    "        one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "        one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "        one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "        return one_hot\n",
    "\n",
    "    def get_data(self):\n",
    "        self.char_tokenize()\n",
    "        return self.train_data, self.val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded chars in train: [49 51 41 14  3 25 64 51  3 51  5 57 53 37 44  4 57 66 29 41 57 25 33 57\n",
      " 25  6 41 29 21 57 57 42 25 36 53 31 25 66 11 41  3  7 57 41 20 25  7 57\n",
      " 36 41 25 13 57 25 14  6 57 36 10 38 44 44 22 23 23 37 44 30  6 57 36 10\n",
      " 20 25 14  6 57 36 10 38 44 44 49 51 41 14  3 25 64 51  3 51  5 57 53 37\n",
      " 44 28 29 11]\n",
      "Number of chars in vocab:  67\n",
      "Train text:  First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "data = Dataset()\n",
    "train_data, val_data = data.get_data()\n",
    "print(\"Encoded chars in train:\", train_data[:100])\n",
    "print(\"Number of chars in vocab: \", len(data.chars))\n",
    "print(\"Train text: \", data.text_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    '''\n",
    "    Load data from dataset in batches (batches = n_seqs * n_steps)\n",
    "    '''\n",
    "    def __init__(self, train, val):\n",
    "        self.train = train\n",
    "        self.val = val\n",
    "\n",
    "    def __call__(self, arr, n_seqs, n_steps):\n",
    "        '''\n",
    "        Create a generator that returns batches of size\n",
    "        n_seqs x n_steps from arr.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        arr: np.array\n",
    "            Array you want to make batches from\n",
    "        n_seqs: int\n",
    "            Batch size, the number of sequences per batch\n",
    "        n_steps: int\n",
    "            Number of sequence steps per batch\n",
    "        '''\n",
    "        batch_size = n_seqs * n_steps\n",
    "        n_batches = len(arr) // batch_size\n",
    "        arr = arr[:n_batches * batch_size]\n",
    "        arr = arr.reshape((n_seqs, -1))\n",
    "        \n",
    "        for n in range(0, arr.shape[1], n_steps):\n",
    "            x = arr[:, n: n + n_steps]\n",
    "            y = np.zeros_like(x)\n",
    "            try:\n",
    "                y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n + n_steps]\n",
    "            except IndexError:\n",
    "                y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[49, 51, 41, 14,  3]]), array([[51, 41, 14,  3, 25]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader(train_data, val_data)\n",
    "next(data_loader(train_data, 1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6996669039b24f13aef7be20d9606477de00a70217801a8b6318938f205f3171"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
